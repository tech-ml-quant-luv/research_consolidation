{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "441df82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING STOCK DATA\n",
      "================================================================================\n",
      "✓ Loaded ADANIPORTS: 53855 candles\n",
      "✓ Loaded AXISBANK: 53855 candles\n",
      "✓ Loaded INFY: 53857 candles\n",
      "\n",
      "================================================================================\n",
      "CALCULATING FEATURES\n",
      "================================================================================\n",
      "✓ Calculated features for ADANIPORTS\n",
      "✓ Calculated features for AXISBANK\n",
      "✓ Calculated features for INFY\n",
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE STOCK CHARACTERIZATION - OHLCV ONLY\n",
      "================================================================================\n",
      "\n",
      "Analyzing ADANIPORTS...\n",
      "\n",
      "Analyzing AXISBANK...\n",
      "\n",
      "Analyzing INFY...\n",
      "\n",
      "✓ Detailed characteristics saved to 'stock_characteristics_detailed.csv'\n",
      "✓ Analyzed 9 stock-year combinations\n",
      "✓ Stocks analyzed: ['ADANIPORTS', 'AXISBANK', 'INFY']\n",
      "\n",
      "================================================================================\n",
      "STATISTICAL TESTS - COMPARING STOCK NATURES\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TEST 1: Mean Reversion Strength by Stock\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Hurst Exponent (Lower = More Mean Reverting):\n",
      "            hurst_exponent  mean_reversion_strength  autocorr_lag1  \\\n",
      "symbol                                                               \n",
      "AXISBANK            0.4958                   0.0082        -0.0221   \n",
      "INFY                0.4998                  -0.0004         0.0035   \n",
      "ADANIPORTS          0.5008                   0.0099        -0.0104   \n",
      "\n",
      "            half_life_periods  \n",
      "symbol                         \n",
      "AXISBANK               0.6783  \n",
      "INFY                   0.6960  \n",
      "ADANIPORTS             0.6862  \n",
      "\n",
      "----------------------------------------\n",
      "Stock Classification:\n",
      "----------------------------------------\n",
      "AXISBANK       : H=0.496 → Moderate Mean Reversion ✓✓\n",
      "INFY           : H=0.500 → Moderate Mean Reversion ✓✓\n",
      "ADANIPORTS     : H=0.501 → Weak/Random ✓\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TEST 2: Volatility Characteristics\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Volatility Stability (Lower CV = More Stable):\n",
      "            atr_mean  atr_cv  vol_autocorr_lag1\n",
      "symbol                                         \n",
      "AXISBANK      2.2546  0.4306             0.3918\n",
      "INFY          2.9414  0.4944             0.3363\n",
      "ADANIPORTS    3.1333  0.6147             0.4680\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TEST 3: Support/Resistance Quality\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "S/R Stability (Higher = Better):\n",
      "            sr_stability_score  sr_range_persistence\n",
      "symbol                                              \n",
      "AXISBANK                1.2830                0.9310\n",
      "INFY                    1.0107                0.9244\n",
      "ADANIPORTS              0.9399                0.9471\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TEST 4: Range vs Trend Behavior\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Time in Range (Higher = Better for Mean Reversion):\n",
      "            time_ranging_pct  trend_strength\n",
      "symbol                                      \n",
      "ADANIPORTS           18.7881          0.6759\n",
      "AXISBANK             18.0268          0.6889\n",
      "INFY                 17.9220          0.5015\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import kstest, normaltest, jarque_bera, kurtosis, skew\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: LOAD DATA\n",
    "# ============================================================================\n",
    "\n",
    "def load_stock_data(symbols, timeframe=5):\n",
    "    \"\"\"Load data for multiple stocks\"\"\"\n",
    "    stock_data = {}\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        try:\n",
    "            df = pd.read_parquet(\n",
    "                f\"s3://quant-ohlcv-data/ohlcv/timeframe={timeframe}min/symbol={symbol}/\"\n",
    "            )\n",
    "            if \"datetime\" in df.columns:\n",
    "                df = df.set_index(\"datetime\")\n",
    "            \n",
    "            start_date = pd.Timestamp(\"2023-02-01\", tz=\"Asia/Kolkata\")\n",
    "            end_date = pd.Timestamp(\"2025-12-31\", tz=\"Asia/Kolkata\")\n",
    "            df = df.loc[start_date:end_date]\n",
    "            \n",
    "            stock_data[symbol] = df\n",
    "            print(f\"✓ Loaded {symbol}: {len(df)} candles\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Failed to load {symbol}: {e}\")\n",
    "    \n",
    "    return stock_data\n",
    "\n",
    "# symbols = [\"ADANIPORTS\", \"AXISBANK\", \"HINDALCO\", \"ICICIBANK\", \n",
    "#            \"INFY\", \"M&M\", \"RELIANCE\", \"POWERGRID\", \"SBIN\", \"HDFCBANK\"]\n",
    "symbols = [\"ADANIPORTS\", \"AXISBANK\", \"HINDALCO\", \"ICICIBANK\", \n",
    "           \"INFY\", \"M&M\", \"RELIANCE\", \"POWERGRID\", \"SBIN\", \"HDFCBANK\"]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LOADING STOCK DATA\")\n",
    "print(\"=\"*80)\n",
    "stock_data = load_stock_data(symbols)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: CALCULATE FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_rsi(prices, period=14):\n",
    "    \"\"\"Calculate RSI\"\"\"\n",
    "    delta = prices.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def calculate_bollinger_position(prices, window=20):\n",
    "    \"\"\"Calculate position within Bollinger Bands (0-1 scale)\"\"\"\n",
    "    ma = prices.rolling(window).mean()\n",
    "    std = prices.rolling(window).std()\n",
    "    upper = ma + 2 * std\n",
    "    lower = ma - 2 * std\n",
    "    position = (prices - lower) / (upper - lower)\n",
    "    return position.clip(0, 1)\n",
    "\n",
    "def calculate_features(df, symbol):\n",
    "    \"\"\"Calculate all relevant features for a stock\"\"\"\n",
    "    df = df.copy()\n",
    "    df['symbol'] = symbol\n",
    "    df['year'] = df.index.year\n",
    "    \n",
    "    # Price-based features\n",
    "    df['returns'] = df['close'].pct_change()\n",
    "    df['log_returns'] = np.log(df['close'] / df['close'].shift(1))\n",
    "    df['range'] = df['high'] - df['low']\n",
    "    df['range_pct'] = (df['range'] / df['close']) * 100\n",
    "    \n",
    "    # Volatility features\n",
    "    df['h-l'] = df['high'] - df['low']\n",
    "    df['h-pc'] = abs(df['high'] - df['close'].shift(1))\n",
    "    df['l-pc'] = abs(df['low'] - df['close'].shift(1))\n",
    "    df['tr'] = df[['h-l', 'h-pc', 'l-pc']].max(axis=1)\n",
    "    df['atr_14'] = df['tr'].rolling(window=14).mean()\n",
    "    df['atr_50'] = df['tr'].rolling(window=50).mean()\n",
    "    \n",
    "    # Support/Resistance levels\n",
    "    df['support_10'] = df['close'].rolling(window=10).min()\n",
    "    df['resistance_10'] = df['close'].rolling(window=10).max()\n",
    "    df['sr_range'] = df['resistance_10'] - df['support_10']\n",
    "    df['sr_range_pct'] = (df['sr_range'] / df['close']) * 100\n",
    "    df['distance_from_support'] = (df['close'] - df['support_10']) / df['close'] * 100\n",
    "    df['distance_from_resistance'] = (df['resistance_10'] - df['close']) / df['close'] * 100\n",
    "    \n",
    "    # Volume features\n",
    "    df['volume_ma_20'] = df['volume'].rolling(window=20).mean()\n",
    "    df['volume_ratio'] = df['volume'] / df['volume_ma_20']\n",
    "    \n",
    "    # Momentum features\n",
    "    df['rsi_14'] = calculate_rsi(df['close'], 14)\n",
    "    df['momentum_5'] = df['close'].pct_change(5)\n",
    "    df['momentum_20'] = df['close'].pct_change(20)\n",
    "    \n",
    "    # Volatility regime\n",
    "    df['volatility_percentile'] = df['atr_14'].rolling(window=252).apply(\n",
    "        lambda x: stats.percentileofscore(x, x.iloc[-1]) if len(x) > 0 else np.nan\n",
    "    )\n",
    "    \n",
    "    # Mean reversion indicators\n",
    "    df['distance_from_ma_20'] = (df['close'] - df['close'].rolling(20).mean()) / df['close'] * 100\n",
    "    df['bollinger_position'] = calculate_bollinger_position(df['close'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CALCULATING FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "enriched_data = {}\n",
    "for symbol, df in stock_data.items():\n",
    "    enriched_data[symbol] = calculate_features(df, symbol)\n",
    "    print(f\"✓ Calculated features for {symbol}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: STOCK CHARACTERIZATION\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_hurst_exponent(prices, max_lag=20):\n",
    "    \"\"\"Calculate Hurst Exponent\"\"\"\n",
    "    if len(prices) < 100:\n",
    "        return np.nan\n",
    "    \n",
    "    lags = range(2, min(max_lag, len(prices) // 2))\n",
    "    tau = []\n",
    "    \n",
    "    for lag in lags:\n",
    "        pp = np.subtract(prices[lag:], prices[:-lag])\n",
    "        tau.append(np.std(pp))\n",
    "    \n",
    "    try:\n",
    "        if len(tau) > 0:\n",
    "            poly = np.polyfit(np.log(lags), np.log(tau), 1)\n",
    "            return poly[0]\n",
    "        else:\n",
    "            return np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def calculate_half_life(returns):\n",
    "    \"\"\"Calculate half-life of mean reversion\"\"\"\n",
    "    if len(returns) < 50:\n",
    "        return np.nan\n",
    "    \n",
    "    returns_lag = np.roll(returns, 1)\n",
    "    returns_lag[0] = 0\n",
    "    returns_diff = returns - returns_lag\n",
    "    \n",
    "    try:\n",
    "        from scipy import stats as sp_stats\n",
    "        slope, _, _, _, _ = sp_stats.linregress(returns_lag[1:], returns_diff[1:])\n",
    "        \n",
    "        if slope >= 0:\n",
    "            return np.nan\n",
    "        \n",
    "        half_life = -np.log(2) / slope\n",
    "        return half_life if half_life > 0 and half_life < 1000 else np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def calculate_price_efficiency(prices):\n",
    "    \"\"\"Calculate price movement efficiency\"\"\"\n",
    "    if len(prices) < 10:\n",
    "        return np.nan\n",
    "    \n",
    "    direct_distance = abs(prices[-1] - prices[0])\n",
    "    actual_distance = np.sum(np.abs(np.diff(prices)))\n",
    "    \n",
    "    if actual_distance == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    return direct_distance / actual_distance\n",
    "\n",
    "def calculate_regime_persistence(percentiles):\n",
    "    \"\"\"Calculate volatility regime persistence\"\"\"\n",
    "    if len(percentiles) < 10:\n",
    "        return np.nan\n",
    "    \n",
    "    regimes = np.where(percentiles > 75, 2, np.where(percentiles < 25, 0, 1))\n",
    "    changes = np.sum(np.diff(regimes) != 0)\n",
    "    persistence = 1 - (changes / len(regimes))\n",
    "    return persistence\n",
    "\n",
    "def comprehensive_stock_characterization(enriched_data):\n",
    "    \"\"\"Analyze inherent market characteristics of stocks\"\"\"\n",
    "    \n",
    "    characteristics = []\n",
    "    \n",
    "    for symbol, df in enriched_data.items():\n",
    "        print(f\"\\nAnalyzing {symbol}...\")\n",
    "        \n",
    "        for year in [2023, 2024, 2025]:\n",
    "            year_df = df[df['year'] == year].dropna(subset=['close', 'returns'])\n",
    "            \n",
    "            if len(year_df) < 100:\n",
    "                continue\n",
    "            \n",
    "            # Volatility characteristics\n",
    "            atr = year_df['atr_14'].dropna()\n",
    "            \n",
    "            vol_characteristics = {\n",
    "                'symbol': symbol,\n",
    "                'year': year,\n",
    "                'atr_mean': atr.mean(),\n",
    "                'atr_std': atr.std(),\n",
    "                'atr_cv': atr.std() / atr.mean() if atr.mean() > 0 else np.nan,\n",
    "                'atr_skewness': skew(atr) if len(atr) > 3 else np.nan,\n",
    "                'atr_kurtosis': kurtosis(atr) if len(atr) > 3 else np.nan,\n",
    "                'vol_autocorr_lag1': year_df['tr'].autocorr(lag=1),\n",
    "                'vol_autocorr_lag5': year_df['tr'].autocorr(lag=5),\n",
    "            }\n",
    "            \n",
    "            # Price action characteristics\n",
    "            returns = year_df['returns'].dropna()\n",
    "            jb_stat, jb_pval = jarque_bera(returns) if len(returns) > 20 else (np.nan, np.nan)\n",
    "            norm_stat, norm_pval = normaltest(returns) if len(returns) > 20 else (np.nan, np.nan)\n",
    "            \n",
    "            price_characteristics = {\n",
    "                'return_mean': returns.mean() * 252,\n",
    "                'return_std': returns.std() * np.sqrt(252),\n",
    "                'return_skewness': skew(returns) if len(returns) > 3 else np.nan,\n",
    "                'return_kurtosis': kurtosis(returns) if len(returns) > 3 else np.nan,\n",
    "                'return_jarque_bera_stat': jb_stat,\n",
    "                'return_jarque_bera_pval': jb_pval,\n",
    "                'has_fat_tails': 'Yes' if jb_pval < 0.05 else 'No' if not np.isnan(jb_pval) else 'Unknown',\n",
    "                'return_normality_pval': norm_pval,\n",
    "                'is_normal': 'Yes' if norm_pval > 0.05 else 'No' if not np.isnan(norm_pval) else 'Unknown',\n",
    "            }\n",
    "            \n",
    "            # Mean reversion characteristics\n",
    "            autocorr_lags = {}\n",
    "            for lag in [1, 2, 3, 5, 10, 20]:\n",
    "                autocorr_lags[f'autocorr_lag{lag}'] = returns.autocorr(lag=lag)\n",
    "            \n",
    "            hurst = calculate_hurst_exponent(year_df['close'].values)\n",
    "            half_life = calculate_half_life(returns.values)\n",
    "            \n",
    "            mean_reversion_characteristics = {\n",
    "                **autocorr_lags,\n",
    "                'hurst_exponent': hurst,\n",
    "                'half_life_periods': half_life,\n",
    "                'mean_reversion_strength': -np.mean([autocorr_lags[f'autocorr_lag{i}'] for i in [1, 2, 3, 5] if not np.isnan(autocorr_lags[f'autocorr_lag{i}'])]),\n",
    "                'is_mean_reverting': 'Strong' if hurst < 0.4 else 'Weak' if hurst < 0.5 else 'Trending' if not np.isnan(hurst) else 'Unknown',\n",
    "            }\n",
    "            \n",
    "            # S/R characteristics\n",
    "            sr_range = year_df['sr_range_pct'].dropna()\n",
    "            \n",
    "            sr_characteristics = {\n",
    "                'sr_range_mean': sr_range.mean(),\n",
    "                'sr_range_std': sr_range.std(),\n",
    "                'sr_range_cv': sr_range.std() / sr_range.mean() if sr_range.mean() > 0 else np.nan,\n",
    "                'sr_stability_score': sr_range.mean() / sr_range.std() if sr_range.std() > 0 else np.nan,\n",
    "                'price_near_support_pct': (year_df['distance_from_support'] < 1).sum() / len(year_df) * 100,\n",
    "                'price_near_resistance_pct': (year_df['distance_from_resistance'] < 1).sum() / len(year_df) * 100,\n",
    "                'sr_range_persistence': year_df['sr_range_pct'].autocorr(lag=1),\n",
    "            }\n",
    "            \n",
    "            # Trend/range characteristics\n",
    "            price_series = year_df['close'].values\n",
    "            time_index = np.arange(len(price_series))\n",
    "            trend_strength = abs(np.corrcoef(time_index, price_series)[0, 1]) if len(price_series) > 2 else np.nan\n",
    "            \n",
    "            bb_position = year_df['bollinger_position'].dropna()\n",
    "            time_trending_pct = ((bb_position < 0.2) | (bb_position > 0.8)).sum() / len(bb_position) * 100 if len(bb_position) > 0 else np.nan\n",
    "            time_ranging_pct = ((bb_position >= 0.4) & (bb_position <= 0.6)).sum() / len(bb_position) * 100 if len(bb_position) > 0 else np.nan\n",
    "            \n",
    "            trend_characteristics = {\n",
    "                'trend_strength': trend_strength,\n",
    "                'time_trending_pct': time_trending_pct,\n",
    "                'time_ranging_pct': time_ranging_pct,\n",
    "                'price_efficiency': calculate_price_efficiency(year_df['close'].values),\n",
    "            }\n",
    "            \n",
    "            # Microstructure characteristics\n",
    "            spread_proxy = year_df['range_pct']\n",
    "            price_changes = year_df['close'].diff().dropna()\n",
    "            \n",
    "            microstructure_characteristics = {\n",
    "                'avg_spread_pct': spread_proxy.mean(),\n",
    "                'spread_volatility': spread_proxy.std(),\n",
    "                'avg_tick_size': np.median(np.abs(price_changes[price_changes != 0])) if len(price_changes[price_changes != 0]) > 0 else np.nan,\n",
    "                'zero_return_pct': (returns == 0).sum() / len(returns) * 100,\n",
    "                'volume_mean': year_df['volume'].mean(),\n",
    "                'volume_std': year_df['volume'].std(),\n",
    "                'volume_cv': year_df['volume'].std() / year_df['volume'].mean() if year_df['volume'].mean() > 0 else np.nan,\n",
    "                'volume_price_corr': year_df['volume'].corr(year_df['close']),\n",
    "                'volume_volatility_corr': year_df['volume'].corr(year_df['atr_14']),\n",
    "            }\n",
    "            \n",
    "            # Regime characteristics\n",
    "            vol_percentile = year_df['volatility_percentile'].dropna()\n",
    "            \n",
    "            regime_characteristics = {\n",
    "                'high_vol_regime_pct': (vol_percentile > 75).sum() / len(vol_percentile) * 100 if len(vol_percentile) > 0 else np.nan,\n",
    "                'low_vol_regime_pct': (vol_percentile < 25).sum() / len(vol_percentile) * 100 if len(vol_percentile) > 0 else np.nan,\n",
    "                'medium_vol_regime_pct': ((vol_percentile >= 25) & (vol_percentile <= 75)).sum() / len(vol_percentile) * 100 if len(vol_percentile) > 0 else np.nan,\n",
    "                'regime_persistence': calculate_regime_persistence(vol_percentile.values) if len(vol_percentile) > 10 else np.nan,\n",
    "            }\n",
    "            \n",
    "            # Combine all characteristics\n",
    "            stock_char = {\n",
    "                **vol_characteristics,\n",
    "                **price_characteristics,\n",
    "                **mean_reversion_characteristics,\n",
    "                **sr_characteristics,\n",
    "                **trend_characteristics,\n",
    "                **microstructure_characteristics,\n",
    "                **regime_characteristics\n",
    "            }\n",
    "            \n",
    "            characteristics.append(stock_char)\n",
    "    \n",
    "    return pd.DataFrame(characteristics)\n",
    "\n",
    "# ============================================================================\n",
    "# RUN ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE STOCK CHARACTERIZATION - OHLCV ONLY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "stock_characteristics = comprehensive_stock_characterization(enriched_data)\n",
    "\n",
    "# Save results\n",
    "stock_characteristics.to_csv('stock_characteristics_detailed.csv', index=False)\n",
    "print(\"\\n✓ Detailed characteristics saved to 'stock_characteristics_detailed.csv'\")\n",
    "print(f\"✓ Analyzed {len(stock_characteristics)} stock-year combinations\")\n",
    "print(f\"✓ Stocks analyzed: {stock_characteristics['symbol'].unique().tolist()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STATISTICAL TESTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTICAL TESTS - COMPARING STOCK NATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test 1: Mean Reversion\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"TEST 1: Mean Reversion Strength by Stock\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "mr_summary = stock_characteristics.groupby('symbol').agg({\n",
    "    'hurst_exponent': 'mean',\n",
    "    'mean_reversion_strength': 'mean',\n",
    "    'autocorr_lag1': 'mean',\n",
    "    'half_life_periods': 'mean'\n",
    "}).round(4)\n",
    "\n",
    "mr_summary = mr_summary.sort_values('hurst_exponent')\n",
    "print(\"\\nHurst Exponent (Lower = More Mean Reverting):\")\n",
    "print(mr_summary)\n",
    "\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Stock Classification:\")\n",
    "print(\"-\"*40)\n",
    "for symbol in mr_summary.index:\n",
    "    hurst = mr_summary.loc[symbol, 'hurst_exponent']\n",
    "    if pd.notna(hurst):\n",
    "        if hurst < 0.45:\n",
    "            classification = \"STRONG Mean Reversion ✓✓✓\"\n",
    "        elif hurst < 0.50:\n",
    "            classification = \"Moderate Mean Reversion ✓✓\"\n",
    "        elif hurst < 0.55:\n",
    "            classification = \"Weak/Random ✓\"\n",
    "        else:\n",
    "            classification = \"TRENDING ✗\"\n",
    "        print(f\"{symbol:15s}: H={hurst:.3f} → {classification}\")\n",
    "\n",
    "# Test 2: Volatility\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"TEST 2: Volatility Characteristics\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "vol_summary = stock_characteristics.groupby('symbol').agg({\n",
    "    'atr_mean': 'mean',\n",
    "    'atr_cv': 'mean',\n",
    "    'vol_autocorr_lag1': 'mean',\n",
    "}).round(4)\n",
    "\n",
    "vol_summary = vol_summary.sort_values('atr_cv')\n",
    "print(\"\\nVolatility Stability (Lower CV = More Stable):\")\n",
    "print(vol_summary)\n",
    "\n",
    "# Test 3: S/R Quality\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"TEST 3: Support/Resistance Quality\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "sr_summary = stock_characteristics.groupby('symbol').agg({\n",
    "    'sr_stability_score': 'mean',\n",
    "    'sr_range_persistence': 'mean',\n",
    "}).round(4)\n",
    "\n",
    "sr_summary = sr_summary.sort_values('sr_stability_score', ascending=False)\n",
    "print(\"\\nS/R Stability (Higher = Better):\")\n",
    "print(sr_summary)\n",
    "\n",
    "# Test 4: Ranging Behavior\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"TEST 4: Range vs Trend Behavior\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "trend_summary = stock_characteristics.groupby('symbol').agg({\n",
    "    'time_ranging_pct': 'mean',\n",
    "    'trend_strength': 'mean',\n",
    "}).round(4)\n",
    "\n",
    "trend_summary = trend_summary.sort_values('time_ranging_pct', ascending=False)\n",
    "print(\"\\nTime in Range (Higher = Better for Mean Reversion):\")\n",
    "print(trend_summary)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9643a9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE STOCK CHARACTERIZATION - OHLCV ONLY\n",
      "================================================================================\n",
      "\n",
      "Analyzing ADANIPORTS...\n",
      "\n",
      "Analyzing AXISBANK...\n",
      "\n",
      "Analyzing INFY...\n",
      "\n",
      "✓ Detailed characteristics saved to 'stock_characteristics_detailed.csv'\n",
      "\n",
      "✓ Analyzed 9 stock-year combinations\n",
      "✓ Stocks analyzed: ['ADANIPORTS', 'AXISBANK', 'INFY']\n",
      "\n",
      "================================================================================\n",
      "STATISTICAL TESTS - COMPARING STOCK NATURES\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TEST 1: Mean Reversion Strength by Stock\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Hurst Exponent (Lower = More Mean Reverting):\n",
      "            hurst_exponent  mean_reversion_strength  autocorr_lag1  \\\n",
      "symbol                                                               \n",
      "AXISBANK            0.4958                   0.0082        -0.0221   \n",
      "INFY                0.4998                  -0.0004         0.0035   \n",
      "ADANIPORTS          0.5008                   0.0099        -0.0104   \n",
      "\n",
      "            half_life_periods  \n",
      "symbol                         \n",
      "AXISBANK               0.6783  \n",
      "INFY                   0.6960  \n",
      "ADANIPORTS             0.6862  \n",
      "\n",
      "----------------------------------------\n",
      "Stock Classification by Mean Reversion:\n",
      "----------------------------------------\n",
      "AXISBANK       : H=0.496 → Moderate Mean Reversion ✓✓\n",
      "INFY           : H=0.500 → Moderate Mean Reversion ✓✓\n",
      "ADANIPORTS     : H=0.501 → Weak Mean Reversion / Random ✓\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import kstest, normaltest, jarque_bera, kurtosis, skew\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ============================================================================\n",
    "# PURE OHLCV-BASED STATISTICAL ANALYSIS\n",
    "# Stock Nature Characterization (No Backtest Data Needed)\n",
    "# ============================================================================\n",
    "\n",
    "def comprehensive_stock_characterization(enriched_data):\n",
    "    \"\"\"\n",
    "    Analyze inherent market characteristics of stocks\n",
    "    \"\"\"\n",
    "    \n",
    "    characteristics = []\n",
    "    \n",
    "    for symbol, df in enriched_data.items():\n",
    "        print(f\"\\nAnalyzing {symbol}...\")\n",
    "        \n",
    "        for year in [2023, 2024, 2025]:\n",
    "            year_df = df[df['year'] == year].dropna(subset=['close', 'returns'])\n",
    "            \n",
    "            if len(year_df) < 100:\n",
    "                continue\n",
    "            \n",
    "            # ================================================================\n",
    "            # 1. VOLATILITY CHARACTERISTICS\n",
    "            # ================================================================\n",
    "            atr = year_df['atr_14'].dropna()\n",
    "            \n",
    "            vol_characteristics = {\n",
    "                'symbol': symbol,\n",
    "                'year': year,\n",
    "                \n",
    "                # Basic volatility\n",
    "                'atr_mean': atr.mean(),\n",
    "                'atr_std': atr.std(),\n",
    "                'atr_cv': atr.std() / atr.mean() if atr.mean() > 0 else np.nan,  # Coefficient of variation\n",
    "                'atr_skewness': skew(atr) if len(atr) > 3 else np.nan,\n",
    "                'atr_kurtosis': kurtosis(atr) if len(atr) > 3 else np.nan,\n",
    "                \n",
    "                # Volatility clustering (GARCH-like)\n",
    "                'vol_autocorr_lag1': year_df['tr'].autocorr(lag=1),\n",
    "                'vol_autocorr_lag5': year_df['tr'].autocorr(lag=5),\n",
    "            }\n",
    "            \n",
    "            # ================================================================\n",
    "            # 2. PRICE ACTION CHARACTERISTICS\n",
    "            # ================================================================\n",
    "            returns = year_df['returns'].dropna()\n",
    "            \n",
    "            # Only calculate if we have enough data\n",
    "            jb_stat, jb_pval = jarque_bera(returns) if len(returns) > 20 else (np.nan, np.nan)\n",
    "            norm_stat, norm_pval = normaltest(returns) if len(returns) > 20 else (np.nan, np.nan)\n",
    "            \n",
    "            price_characteristics = {\n",
    "                # Return distribution\n",
    "                'return_mean': returns.mean() * 252,  # Annualized\n",
    "                'return_std': returns.std() * np.sqrt(252),  # Annualized\n",
    "                'return_skewness': skew(returns) if len(returns) > 3 else np.nan,\n",
    "                'return_kurtosis': kurtosis(returns) if len(returns) > 3 else np.nan,  # Excess kurtosis\n",
    "                \n",
    "                # Fat tails test\n",
    "                'return_jarque_bera_stat': jb_stat,\n",
    "                'return_jarque_bera_pval': jb_pval,\n",
    "                'has_fat_tails': 'Yes' if jb_pval < 0.05 else 'No' if not np.isnan(jb_pval) else 'Unknown',\n",
    "                \n",
    "                # Normality test\n",
    "                'return_normality_pval': norm_pval,\n",
    "                'is_normal': 'Yes' if norm_pval > 0.05 else 'No' if not np.isnan(norm_pval) else 'Unknown',\n",
    "            }\n",
    "            \n",
    "            # ================================================================\n",
    "            # 3. MEAN REVERSION CHARACTERISTICS\n",
    "            # ================================================================\n",
    "            \n",
    "            # Autocorrelation at multiple lags\n",
    "            autocorr_lags = {}\n",
    "            for lag in [1, 2, 3, 5, 10, 20]:\n",
    "                autocorr = returns.autocorr(lag=lag)\n",
    "                autocorr_lags[f'autocorr_lag{lag}'] = autocorr\n",
    "            \n",
    "            # Hurst exponent (mean reversion indicator)\n",
    "            # H < 0.5 = mean reverting, H = 0.5 = random walk, H > 0.5 = trending\n",
    "            hurst = calculate_hurst_exponent(year_df['close'].values)\n",
    "            \n",
    "            # Half-life of mean reversion\n",
    "            half_life = calculate_half_life(returns.values)\n",
    "            \n",
    "            mean_reversion_characteristics = {\n",
    "                **autocorr_lags,\n",
    "                'hurst_exponent': hurst,\n",
    "                'half_life_periods': half_life,\n",
    "                'mean_reversion_strength': -np.mean([autocorr_lags[f'autocorr_lag{i}'] for i in [1, 2, 3, 5] if not np.isnan(autocorr_lags[f'autocorr_lag{i}'])]),\n",
    "                'is_mean_reverting': 'Strong' if hurst < 0.4 else 'Weak' if hurst < 0.5 else 'Trending' if not np.isnan(hurst) else 'Unknown',\n",
    "            }\n",
    "            \n",
    "            # ================================================================\n",
    "            # 4. SUPPORT/RESISTANCE CHARACTERISTICS\n",
    "            # ================================================================\n",
    "            \n",
    "            sr_range = year_df['sr_range_pct'].dropna()\n",
    "            \n",
    "            sr_characteristics = {\n",
    "                # S/R level stability\n",
    "                'sr_range_mean': sr_range.mean(),\n",
    "                'sr_range_std': sr_range.std(),\n",
    "                'sr_range_cv': sr_range.std() / sr_range.mean() if sr_range.mean() > 0 else np.nan,\n",
    "                'sr_stability_score': sr_range.mean() / sr_range.std() if sr_range.std() > 0 else np.nan,\n",
    "                \n",
    "                # How often price is near S/R\n",
    "                'price_near_support_pct': (year_df['distance_from_support'] < 1).sum() / len(year_df) * 100 if 'distance_from_support' in year_df else np.nan,\n",
    "                'price_near_resistance_pct': (year_df['distance_from_resistance'] < 1).sum() / len(year_df) * 100 if 'distance_from_resistance' in year_df else np.nan,\n",
    "                \n",
    "                # S/R respect (how often they hold)\n",
    "                'sr_range_persistence': year_df['sr_range_pct'].autocorr(lag=1),\n",
    "            }\n",
    "            \n",
    "            # ================================================================\n",
    "            # 5. TREND/RANGE CHARACTERISTICS\n",
    "            # ================================================================\n",
    "            \n",
    "            # Calculate trend strength directly from price\n",
    "            price_series = year_df['close'].values\n",
    "            time_index = np.arange(len(price_series))\n",
    "            trend_strength = abs(np.corrcoef(time_index, price_series)[0, 1]) if len(price_series) > 2 else np.nan\n",
    "            \n",
    "            # Percentage of time in trending vs ranging\n",
    "            # Using bollinger band position if available\n",
    "            if 'bollinger_position' in year_df.columns:\n",
    "                bb_position = year_df['bollinger_position'].dropna()\n",
    "                time_trending_pct = ((bb_position < 0.2) | (bb_position > 0.8)).sum() / len(bb_position) * 100 if len(bb_position) > 0 else np.nan\n",
    "                time_ranging_pct = ((bb_position >= 0.4) & (bb_position <= 0.6)).sum() / len(bb_position) * 100 if len(bb_position) > 0 else np.nan\n",
    "            else:\n",
    "                # Alternative: use distance from moving average\n",
    "                ma_20 = year_df['close'].rolling(20).mean()\n",
    "                distance_from_ma = abs(year_df['close'] - ma_20) / year_df['close'] * 100\n",
    "                time_trending_pct = (distance_from_ma > 2).sum() / len(year_df) * 100\n",
    "                time_ranging_pct = (distance_from_ma < 1).sum() / len(year_df) * 100\n",
    "            \n",
    "            trend_characteristics = {\n",
    "                'trend_strength': trend_strength,\n",
    "                'time_trending_pct': time_trending_pct,\n",
    "                'time_ranging_pct': time_ranging_pct,\n",
    "                \n",
    "                # Price efficiency (straight line / actual path)\n",
    "                'price_efficiency': calculate_price_efficiency(year_df['close'].values),\n",
    "            }\n",
    "            \n",
    "            # ================================================================\n",
    "            # 6. MICROSTRUCTURE CHARACTERISTICS\n",
    "            # ================================================================\n",
    "            \n",
    "            # Spread proxy (high - low as % of close)\n",
    "            spread_proxy = year_df['range_pct']\n",
    "            \n",
    "            # Tick movement analysis\n",
    "            price_changes = year_df['close'].diff().dropna()\n",
    "            \n",
    "            microstructure_characteristics = {\n",
    "                # Liquidity proxies\n",
    "                'avg_spread_pct': spread_proxy.mean(),\n",
    "                'spread_volatility': spread_proxy.std(),\n",
    "                \n",
    "                # Price discreteness\n",
    "                'avg_tick_size': np.median(np.abs(price_changes[price_changes != 0])) if len(price_changes[price_changes != 0]) > 0 else np.nan,\n",
    "                'zero_return_pct': (returns == 0).sum() / len(returns) * 100,\n",
    "                \n",
    "                # Volume characteristics\n",
    "                'volume_mean': year_df['volume'].mean(),\n",
    "                'volume_std': year_df['volume'].std(),\n",
    "                'volume_cv': year_df['volume'].std() / year_df['volume'].mean() if year_df['volume'].mean() > 0 else np.nan,\n",
    "                \n",
    "                # Volume-price relationship\n",
    "                'volume_price_corr': year_df['volume'].corr(year_df['close']),\n",
    "                'volume_volatility_corr': year_df['volume'].corr(year_df['atr_14']),\n",
    "            }\n",
    "            \n",
    "            # ================================================================\n",
    "            # 7. REGIME CHARACTERISTICS\n",
    "            # ================================================================\n",
    "            \n",
    "            if 'volatility_percentile' in year_df.columns:\n",
    "                vol_percentile = year_df['volatility_percentile'].dropna()\n",
    "                \n",
    "                regime_characteristics = {\n",
    "                    # Volatility regime distribution\n",
    "                    'high_vol_regime_pct': (vol_percentile > 75).sum() / len(vol_percentile) * 100 if len(vol_percentile) > 0 else np.nan,\n",
    "                    'low_vol_regime_pct': (vol_percentile < 25).sum() / len(vol_percentile) * 100 if len(vol_percentile) > 0 else np.nan,\n",
    "                    'medium_vol_regime_pct': ((vol_percentile >= 25) & (vol_percentile <= 75)).sum() / len(vol_percentile) * 100 if len(vol_percentile) > 0 else np.nan,\n",
    "                    \n",
    "                    # Regime persistence\n",
    "                    'regime_persistence': calculate_regime_persistence(vol_percentile.values) if len(vol_percentile) > 10 else np.nan,\n",
    "                }\n",
    "            else:\n",
    "                regime_characteristics = {\n",
    "                    'high_vol_regime_pct': np.nan,\n",
    "                    'low_vol_regime_pct': np.nan,\n",
    "                    'medium_vol_regime_pct': np.nan,\n",
    "                    'regime_persistence': np.nan,\n",
    "                }\n",
    "            \n",
    "            # ================================================================\n",
    "            # COMBINE ALL CHARACTERISTICS\n",
    "            # ================================================================\n",
    "            \n",
    "            stock_char = {\n",
    "                **vol_characteristics,\n",
    "                **price_characteristics,\n",
    "                **mean_reversion_characteristics,\n",
    "                **sr_characteristics,\n",
    "                **trend_characteristics,\n",
    "                **microstructure_characteristics,\n",
    "                **regime_characteristics\n",
    "            }\n",
    "            \n",
    "            characteristics.append(stock_char)\n",
    "    \n",
    "    return pd.DataFrame(characteristics)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# HELPER FUNCTIONS FOR ADVANCED METRICS\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_hurst_exponent(prices, max_lag=20):\n",
    "    \"\"\"\n",
    "    Calculate Hurst Exponent\n",
    "    H < 0.5: Mean reverting\n",
    "    H = 0.5: Random walk\n",
    "    H > 0.5: Trending\n",
    "    \"\"\"\n",
    "    if len(prices) < 100:\n",
    "        return np.nan\n",
    "    \n",
    "    lags = range(2, min(max_lag, len(prices) // 2))\n",
    "    tau = []\n",
    "    \n",
    "    for lag in lags:\n",
    "        # Calculate standard deviation of differences\n",
    "        pp = np.subtract(prices[lag:], prices[:-lag])\n",
    "        tau.append(np.std(pp))\n",
    "    \n",
    "    # Linear fit\n",
    "    try:\n",
    "        if len(tau) > 0:\n",
    "            poly = np.polyfit(np.log(lags), np.log(tau), 1)\n",
    "            return poly[0]\n",
    "        else:\n",
    "            return np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def calculate_half_life(returns):\n",
    "    \"\"\"\n",
    "    Calculate half-life of mean reversion (Ornstein-Uhlenbeck)\n",
    "    \"\"\"\n",
    "    if len(returns) < 50:\n",
    "        return np.nan\n",
    "    \n",
    "    # Lag the returns\n",
    "    returns_lag = np.roll(returns, 1)\n",
    "    returns_lag[0] = 0\n",
    "    \n",
    "    # Regression\n",
    "    returns_diff = returns - returns_lag\n",
    "    \n",
    "    try:\n",
    "        # Use returns_lag as predictor\n",
    "        from scipy import stats as sp_stats\n",
    "        slope, _, _, _, _ = sp_stats.linregress(returns_lag[1:], returns_diff[1:])\n",
    "        \n",
    "        if slope >= 0:\n",
    "            return np.nan\n",
    "        \n",
    "        half_life = -np.log(2) / slope\n",
    "        return half_life if half_life > 0 and half_life < 1000 else np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def calculate_price_efficiency(prices):\n",
    "    \"\"\"\n",
    "    Calculate how efficient price movement is\n",
    "    1.0 = straight line, <1.0 = meandering\n",
    "    \"\"\"\n",
    "    if len(prices) < 10:\n",
    "        return np.nan\n",
    "    \n",
    "    # Distance from start to end\n",
    "    direct_distance = abs(prices[-1] - prices[0])\n",
    "    \n",
    "    # Actual path length\n",
    "    actual_distance = np.sum(np.abs(np.diff(prices)))\n",
    "    \n",
    "    if actual_distance == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    efficiency = direct_distance / actual_distance\n",
    "    return efficiency\n",
    "\n",
    "\n",
    "def calculate_regime_persistence(percentiles):\n",
    "    \"\"\"\n",
    "    How long does volatility stay in same regime\n",
    "    \"\"\"\n",
    "    if len(percentiles) < 10:\n",
    "        return np.nan\n",
    "    \n",
    "    # Define regimes\n",
    "    regimes = np.where(percentiles > 75, 2, np.where(percentiles < 25, 0, 1))\n",
    "    \n",
    "    # Count regime changes\n",
    "    changes = np.sum(np.diff(regimes) != 0)\n",
    "    \n",
    "    # Persistence = inverse of change frequency\n",
    "    persistence = 1 - (changes / len(regimes))\n",
    "    return persistence\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# RUN COMPREHENSIVE ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE STOCK CHARACTERIZATION - OHLCV ONLY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "stock_characteristics = comprehensive_stock_characterization(enriched_data)\n",
    "\n",
    "# Save to CSV for inspection\n",
    "stock_characteristics.to_csv('stock_characteristics_detailed.csv', index=False)\n",
    "print(\"\\n✓ Detailed characteristics saved to 'stock_characteristics_detailed.csv'\")\n",
    "\n",
    "print(f\"\\n✓ Analyzed {len(stock_characteristics)} stock-year combinations\")\n",
    "print(f\"✓ Stocks analyzed: {stock_characteristics['symbol'].unique().tolist()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STATISTICAL COMPARISONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTICAL TESTS - COMPARING STOCK NATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# TEST 1: Mean Reversion Strength Comparison\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"TEST 1: Mean Reversion Strength by Stock\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "mr_summary = stock_characteristics.groupby('symbol').agg({\n",
    "    'hurst_exponent': 'mean',\n",
    "    'mean_reversion_strength': 'mean',\n",
    "    'autocorr_lag1': 'mean',\n",
    "    'half_life_periods': 'mean'\n",
    "}).round(4)\n",
    "\n",
    "mr_summary = mr_summary.sort_values('hurst_exponent')\n",
    "print(\"\\nHurst Exponent (Lower = More Mean Reverting):\")\n",
    "print(mr_summary)\n",
    "\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Stock Classification by Mean Reversion:\")\n",
    "print(\"-\"*40)\n",
    "for symbol in mr_summary.index:\n",
    "    hurst = mr_summary.loc[symbol, 'hurst_exponent']\n",
    "    if pd.notna(hurst):\n",
    "        if hurst < 0.45:\n",
    "            classification = \"STRONG Mean Reversion ✓✓✓\"\n",
    "        elif hurst < 0.50:\n",
    "            classification = \"Moderate Mean Reversion ✓✓\"\n",
    "        elif hurst < 0.55:\n",
    "            classification = \"Weak Mean Reversion / Random ✓\"\n",
    "        else:\n",
    "            classification = \"TRENDING ✗\"\n",
    "        print(f\"{symbol:15s}: H={hurst:.3f} → {classification}\")\n",
    "    else:\n",
    "        print(f\"{symbol:15s}: H=N/A → Insufficient data\")\n",
    "\n",
    "# Rest of the analysis continues...\n",
    "# (I'll provide the rest in the next part to keep it manageable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af8fcb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"../results_json/results_json.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "244ce6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"ADANIPORTS_5\":{\"metadata\":{\"filename\":\"ADANIPORTS\",\"timeframe\":5,\"timestamp\":\"2026-01-27T16:01:16.669595\",\"total_period_years\":2.9103353867,\"starting_capital\":604.75,\"ending_capital\":1684.2231864286,\"total_return_pct\":178.4990800213,\"cagr_pct\":42.1813994967,\"max_drawdown_pct\":-1.7179517353},\"yearly_performance\":[{\"year\":2023,\"Start Equity\":604.75,\"End Equity\":899.6941964286,\"Total Return (%)\":48.771260261,\"Max Drawdown (%)\":-1.4082651339,\"Trades\":213.0,\"Win Rate (%)\":69.9530516432,\"Avg Win\":2.9625222819,\"Avg Loss\":-2.2886191183,\"Sharpe Ratio\":0.7328960446},{\"year\":2024,\"Start Equity\":899.6941964286,\"End Equity\":1256.9132185714,\"Total Return (%)\":39.7044933224,\"Max Drawdown (%)\":-1.7179517353,\"Trades\":220.0,\"Win Rate (%)\":66.8181818182,\"Avg Win\":4.5112333333,\"Avg Loss\":-4.1908531213,\"Sharpe Ratio\":0.5629066316},{\"year\":2025,\"Start Equity\":1256.9132185714,\"End Equity\":1684.2231864286,\"Total Return (%)\":33.9967757156,\"Max Drawdown (%)\":-1.2570854322,\"Trades\":213.0,\"Win Rate (%)\":69.014084507,\"Avg Win\":4.4785119048,\"Avg Loss\":-3.5004739719,\"Sharpe Ratio\":0.6950576612}]},\"AXISBANK_5\":{\"metadata\":{\"filename\":\"AXISBANK\",\"timeframe\":5,\"timestamp\":\"2026-01-27T15:59:02.655619\",\"total_period_years\":2.9103353867,\"starting_capital\":877.0,\"ending_capital\":1707.670225,\"total_return_pct\":94.7172434436,\"cagr_pct\":25.7303797934,\"max_drawdown_pct\":-1.6346041021},\"yearly_performance\":[{\"year\":2023,\"Start Equity\":877.0,\"End Equity\":1113.4081492857,\"Total Return (%)\":26.9564594396,\"Max Drawdown (%)\":-1.2820053313,\"Trades\":235.0,\"Win Rate (%)\":74.8936170213,\"Avg Win\":2.0409468182,\"Avg Loss\":-2.0813303511,\"Sharpe Ratio\":0.8247179388},{\"year\":2024,\"Start Equity\":1113.4081492857,\"End Equity\":1492.0412257143,\"Total Return (%)\":34.0066737136,\"Max Drawdown (%)\":-0.7871333082,\"Trades\":222.0,\"Win Rate (%)\":74.7747747748,\"Avg Win\":3.2111003614,\"Avg Loss\":-2.7573139923,\"Sharpe Ratio\":0.8172279365},{\"year\":2025,\"Start Equity\":1492.0412257143,\"End Equity\":1707.670225,\"Total Return (%)\":14.4519464724,\"Max Drawdown (%)\":-1.6346041021,\"Trades\":232.0,\"Win Rate (%)\":67.2413793103,\"Avg Win\":2.5570701923,\"Avg Loss\":-2.4114993515,\"Sharpe Ratio\":0.5725459126}]},\"INFY_5\":{\"metadata\":{\"filename\":\"INFY\",\"timeframe\":5,\"timestamp\":\"2026-01-27T16:25:57.718154\",\"total_period_years\":2.9103353867,\"starting_capital\":1533.6,\"ending_capital\":2251.39547,\"total_return_pct\":46.8046081116,\"cagr_pct\":14.1017377652,\"max_drawdown_pct\":-0.8595552918},\"yearly_performance\":[{\"year\":2023,\"Start Equity\":1533.6,\"End Equity\":1692.14471,\"Total Return (%)\":10.3380744653,\"Max Drawdown (%)\":-0.8595552918,\"Trades\":199.0,\"Win Rate (%)\":68.3417085427,\"Avg Win\":2.3466009559,\"Avg Loss\":-2.5490955556,\"Sharpe Ratio\":0.4716070664},{\"year\":2024,\"Start Equity\":1692.14471,\"End Equity\":1993.780575,\"Total Return (%)\":17.8256542255,\"Max Drawdown (%)\":-0.8099886459,\"Trades\":218.0,\"Win Rate (%)\":67.4311926606,\"Avg Win\":3.761152449,\"Avg Loss\":-3.5387823239,\"Sharpe Ratio\":0.5659345682},{\"year\":2025,\"Start Equity\":1993.780575,\"End Equity\":2251.39547,\"Total Return (%)\":12.9209251123,\"Max Drawdown (%)\":-0.8114972529,\"Trades\":194.0,\"Win Rate (%)\":71.6494845361,\"Avg Win\":3.2193988489,\"Avg Loss\":-3.4523917273,\"Sharpe Ratio\":0.5662890302}]}}\n"
     ]
    }
   ],
   "source": [
    "print(df[[\"ADANIPORTS_5\", \"AXISBANK_5\", \"INFY_5\"]].to_json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_consolidation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
